from collections import Counter
import json
import os

def process_json(file_name, key):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€é‡è¤‡ã‚’ã‚«ã‚¦ãƒ³ãƒˆã€å‰Šé™¤ã™ã‚‹"""
    base_dir = os.path.dirname(os.path.abspath(__file__))  # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    file_path = os.path.join(base_dir, file_name)  # çµ¶å¯¾ãƒ‘ã‚¹ã‚’ä½œæˆ

    with open(file_path, "r", encoding="utf-8") as file:
        data = json.load(file)

    key_counts = Counter(item[key] for item in data)
    duplicates = {k: v for k, v in key_counts.items() if v > 1}
    unique_data = list({item[key]: item for item in reversed(data)}.values())


    print(f"\nğŸ“Œ {file_name} ã®è§£æçµæœ")
    print(f"å…ƒã®ãƒ‡ãƒ¼ã‚¿æ•°: {len(data)}")
    print(f"ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ‡ãƒ¼ã‚¿æ•°: {len(unique_data)}")
    print(f"é‡è¤‡ã®åˆè¨ˆä»¶æ•°: {sum(duplicates.values()) - len(duplicates)}")
    
    if duplicates:
        print("é‡è¤‡ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ä¸€è¦§:")
        for k, v in duplicates.items():
            print(f"  {k}: {v}å›")

    # new_file_name = file_name.replace(".json", ".json")
    with open(file_name, "w", encoding="utf-8") as file:
        json.dump(unique_data, file, indent=4, ensure_ascii=False)

    print(f"âœ… é‡è¤‡ã‚’å‰Šé™¤ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ '{file_name}' ã«ä¿å­˜ã—ã¾ã—ãŸï¼")


def check_consistency(file_name, key):
    """æŒ‡å®šã—ãŸã‚­ãƒ¼ã®å€¤ã®ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    with open(file_name, "r", encoding="utf-8") as file:
        data = json.load(file)

    # å„å€¤ã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    value_counts = Counter(item[key] for item in data)

    print(f"\nğŸ“Œ {file_name} ã® '{key}' ãƒã‚§ãƒƒã‚¯")
    for value, count in value_counts.items():
        print(f"  {value}: {count}å›")

# ç©ºæ¸¯ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
check_consistency("airports.json", "country")
check_consistency("airports.json", "area")

# èˆªç©ºä¼šç¤¾ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
check_consistency("airlines.json", "country")

process_json("airports.json", "code")

process_json("airlines.json", "code")
